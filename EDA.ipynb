{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from colorama import Fore, Style\n",
    "import lightgbm, xgboost, catboost\n",
    "import pickle\n",
    "\n",
    "from sklearn.base import clone, BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, PolynomialFeatures, SplineTransformer\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,root_mean_squared_error\n",
    "\n",
    "pd.options.mode.chained_assignment = \"raise\"\n",
    "\n",
    "saved_models, oof_pred = {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping columns: (233234, 814)\n",
      "216 columns are constant. These will be dropped.\n",
      "Shape after dropping columns: (233234, 597)\n",
      "There are 0 missing values.\n",
      "There are 0 duplicates.\n",
      "There are 382 binary columns.\n"
     ]
    }
   ],
   "source": [
    "train = pl.read_csv('datasets/train.csv')\n",
    "print('Shape before dropping columns:', train.shape)\n",
    "\n",
    "constant_columns = np.array(train.columns)[train.select(pl.all().n_unique() == 1).to_numpy().ravel()]\n",
    "print(len(constant_columns), 'columns are constant. These will be dropped.')\n",
    "\n",
    "drop_columns = list(constant_columns) + ['Id']\n",
    "\n",
    "train = train.drop(drop_columns)\n",
    "print('Shape after dropping columns:', train.shape)\n",
    "\n",
    "# Null values\n",
    "print('There are', train.null_count().to_numpy().sum(), 'missing values.')\n",
    "\n",
    "# Duplicates\n",
    "print('There are', len(train) - train.n_unique(), 'duplicates.')\n",
    "\n",
    "# Boolean columns\n",
    "print('There are', train.select(pl.all().n_unique() == 2).to_numpy().sum(), 'binary columns.')\n",
    "\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess(df_polars):\n",
    "    \"\"\"Convert the polars dataframe to pandas; extract target and groups if it is the training dataframe\n",
    "    \n",
    "    The function should be applied to training and test datasets.\n",
    "    \n",
    "    Parameters\n",
    "    df_polars: polars DataFrame (train or test)\n",
    "    \n",
    "    Return values:\n",
    "    df: pandas DataFrame with all features of shape (n_samples, n_features)\n",
    "    target: target array of shape (n_samples, ) or None\n",
    "    groups: grouping array for GroupKFold of shape (n_samples, ) or None\n",
    "    \"\"\"\n",
    "    global cat_mapping\n",
    "    \n",
    "    # Add eight features extracted from player names,\n",
    "    # Drop GameRulesetName, freetext and target columns\n",
    "    df = df_polars.with_columns(\n",
    "        pl.col('agent1').str.extract(r'MCTS-(.*)-(.*)-(.*)-(.*)', 1).alias('p1_selection'),\n",
    "        pl.col('agent1').str.extract(r'MCTS-(.*)-(.*)-(.*)-(.*)', 2).alias('p1_exploration').cast(pl.Float32),\n",
    "        pl.col('agent1').str.extract(r'MCTS-(.*)-(.*)-(.*)-(.*)', 3).alias('p1_playout'),\n",
    "        pl.col('agent1').str.extract(r'MCTS-(.*)-(.*)-(.*)-(.*)', 4).alias('p1_bounds'),\n",
    "        pl.col('agent2').str.extract(r'MCTS-(.*)-(.*)-(.*)-(.*)', 1).alias('p2_selection'),\n",
    "        pl.col('agent2').str.extract(r'MCTS-(.*)-(.*)-(.*)-(.*)', 2).alias('p2_exploration').cast(pl.Float32),\n",
    "        pl.col('agent2').str.extract(r'MCTS-(.*)-(.*)-(.*)-(.*)', 3).alias('p2_playout'),\n",
    "        pl.col('agent2').str.extract(r'MCTS-(.*)-(.*)-(.*)-(.*)', 4).alias('p2_bounds')\n",
    "    ).drop(\n",
    "        ['GameRulesetName', 'EnglishRules', 'LudRules', \n",
    "         'num_wins_agent1', 'num_draws_agent1',\n",
    "         'num_losses_agent1', 'utility_agent1'],\n",
    "        strict=False\n",
    "    ).to_pandas()\n",
    "\n",
    "    if 'utility_agent1' in df_polars.columns: # Processing the training data\n",
    "        # Extract the target\n",
    "        target = df_polars.select('utility_agent1').to_numpy().ravel()\n",
    "\n",
    "        # Extract the groups for the GroupKFold\n",
    "        groups = df_polars.select('GameRulesetName').to_numpy()\n",
    "        \n",
    "        # Set the mapping to categorical dtypes\n",
    "        cat_mapping = {feature: pd.CategoricalDtype(categories=list(set(df[feature]))) for feature in df.columns[df.dtypes == object]}\n",
    "    else: # Processing the test data\n",
    "        target, groups = None, None\n",
    "        \n",
    "    # Convert the strings to categorical\n",
    "    df = df.astype(cat_mapping)\n",
    "\n",
    "    return df, target, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('preprocess.py', 'r').read())\n",
    "train_pd, y, groups = preprocess(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval_kf = GroupKFold()\n",
    "folds = list(crossval_kf.split(train_pd, groups=train.select('GameRulesetName')))\n",
    "    \n",
    "def cross_validate_model(model, features=train_pd.columns, label='', save_models=False):\n",
    "    global oof\n",
    "    start_time = datetime.datetime.now()\n",
    "    oof = np.full_like(y, np.nan)\n",
    "    model_list = []\n",
    "    for fold, (idx_tr, idx_va) in enumerate(folds):\n",
    "        X_tr = train_pd[features].iloc[idx_tr]\n",
    "        X_va = train_pd[features].iloc[idx_va]\n",
    "        y_tr = y[idx_tr]\n",
    "        y_va = y[idx_va]\n",
    "\n",
    "        m = clone(model)\n",
    "        m.fit(X_tr, y_tr)\n",
    "        y_pred = m.predict(X_va).clip(-1, 1)\n",
    "        if save_models:\n",
    "            model_list.append(m)\n",
    "        del m\n",
    "        oof[idx_va] = y_pred\n",
    "        # rmse = mean_squared_error(y_va, y_pred, squared=False)\n",
    "        rmse = root_mean_squared_error(y_va, y_pred)\n",
    "        print(f\"# Fold {fold}: {rmse:=.3f}\")\n",
    "        \n",
    "    elapsed_time = datetime.datetime.now() - start_time\n",
    "    # rmse = mean_squared_error(y, oof, squared=False)\n",
    "    rmse = root_mean_squared_error(y, oof)\n",
    "    print(f\"{Fore.GREEN}# Overall RMSE={rmse:.3f} {label}\"\n",
    "          f\"   {int(np.round(elapsed_time.total_seconds() / 60))} min{Style.RESET_ALL}\")\n",
    "    if save_models:\n",
    "        saved_models[label] = dict(features=features, model_list=model_list)\n",
    "        oof_pred[label] = oof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stochastic</th>\n",
       "      <th>Asymmetric</th>\n",
       "      <th>AsymmetricForces</th>\n",
       "      <th>AsymmetricPiecesType</th>\n",
       "      <th>PlayersWithDirections</th>\n",
       "      <th>Cooperation</th>\n",
       "      <th>Team</th>\n",
       "      <th>Shape</th>\n",
       "      <th>SquareShape</th>\n",
       "      <th>HexShape</th>\n",
       "      <th>...</th>\n",
       "      <th>p1_playout</th>\n",
       "      <th>p1_bounds</th>\n",
       "      <th>p2_selection</th>\n",
       "      <th>p2_exploration</th>\n",
       "      <th>p2_playout</th>\n",
       "      <th>p2_bounds</th>\n",
       "      <th>p_selection</th>\n",
       "      <th>p_exploration</th>\n",
       "      <th>p_playout</th>\n",
       "      <th>p_bounds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>MAST</td>\n",
       "      <td>false</td>\n",
       "      <td>ProgressiveHistory</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Random200</td>\n",
       "      <td>false</td>\n",
       "      <td>ProgressiveHistory-ProgressiveHistory</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>MAST-Random200</td>\n",
       "      <td>false-false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>MAST</td>\n",
       "      <td>false</td>\n",
       "      <td>UCB1GRAVE</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NST</td>\n",
       "      <td>true</td>\n",
       "      <td>ProgressiveHistory-UCB1GRAVE</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>MAST-NST</td>\n",
       "      <td>false-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>MAST</td>\n",
       "      <td>true</td>\n",
       "      <td>UCB1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NST</td>\n",
       "      <td>false</td>\n",
       "      <td>ProgressiveHistory-UCB1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MAST-NST</td>\n",
       "      <td>true-false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stochastic  Asymmetric  AsymmetricForces  AsymmetricPiecesType  \\\n",
       "0           0           0                 0                     0   \n",
       "1           0           0                 0                     0   \n",
       "2           0           0                 0                     0   \n",
       "\n",
       "   PlayersWithDirections  Cooperation  Team  Shape  SquareShape  HexShape  \\\n",
       "0                      0            0     0      1            0         0   \n",
       "1                      0            0     0      1            0         0   \n",
       "2                      0            0     0      1            0         0   \n",
       "\n",
       "   ...  p1_playout  p1_bounds        p2_selection  p2_exploration  p2_playout  \\\n",
       "0  ...        MAST      false  ProgressiveHistory             0.6   Random200   \n",
       "1  ...        MAST      false           UCB1GRAVE             0.6         NST   \n",
       "2  ...        MAST       true                UCB1             0.1         NST   \n",
       "\n",
       "   p2_bounds                            p_selection  p_exploration  \\\n",
       "0      false  ProgressiveHistory-ProgressiveHistory           -0.5   \n",
       "1       true           ProgressiveHistory-UCB1GRAVE           -0.5   \n",
       "2      false                ProgressiveHistory-UCB1            0.0   \n",
       "\n",
       "        p_playout     p_bounds  \n",
       "0  MAST-Random200  false-false  \n",
       "1        MAST-NST   false-true  \n",
       "2        MAST-NST   true-false  \n",
       "\n",
       "[3 rows x 600 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/chenzhuo/anaconda3/envs/comfyui/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# All the game features (concepts) have a ComputationTypeId, which is either 'Compiler' or 'Simulation'\n",
    "concepts = pd.read_csv('datasets/concepts.csv', index_col='Id')\n",
    "concepts[['TypeId', 'DataTypeId', 'ComputationTypeId', 'LeafNode', 'ShowOnWebsite']] = concepts[['TypeId', 'DataTypeId', 'ComputationTypeId', 'LeafNode', 'ShowOnWebsite']].astype(int)\n",
    "concepts.replace({'ComputationTypeId': {1: 'Compiler', 2: 'Simulation'}}, inplace=True)\n",
    "# print(concepts.ComputationTypeId.value_counts())\n",
    "\n",
    "features = [f for f in train_pd.columns if f not in ['agent1', 'agent2']]\n",
    "X = train_pd[features].copy()\n",
    "X['p_selection'] = (X.p1_selection.astype(str) + '-' + X.p2_selection.astype(str)).astype('category')\n",
    "X['p_exploration'] = X.p1_exploration - X.p2_exploration\n",
    "X['p_playout'] = (X.p1_playout.astype(str) + '-' + X.p2_playout.astype(str)).astype('category')\n",
    "X['p_bounds'] = (X.p1_bounds.astype(str) + '-' + X.p2_bounds.astype(str)).astype('category')\n",
    "display(X.head(3))\n",
    "\n",
    "lgbm_params_fast = {'learning_rate': 0.2, 'colsample_bytree': 0.7, 'verbose': 0}\n",
    "model = lightgbm.LGBMRegressor(**lgbm_params_fast)\n",
    "kf = GroupShuffleSplit(n_splits=5, random_state=1)\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(train_pd, groups=groups)):\n",
    "    X_tr = X.iloc[idx_tr]\n",
    "    X_va = X.iloc[idx_va]\n",
    "    y_tr = y[idx_tr]\n",
    "    y_va = y[idx_va]\n",
    "#     model.fit(X_tr, y_tr, eval_set=(X_va, y_va), eval_metric='rmse', callbacks=[lightgbm.log_evaluation()])\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_va)\n",
    "    rmse = mean_squared_error(y_va, y_pred, squared=False)\n",
    "    \n",
    "    result = permutation_importance(model, X_va, y_va, scoring='neg_root_mean_squared_error', n_repeats=2)\n",
    "    \n",
    "    print(f\"{Fore.GREEN}{Style.BRIGHT}Important features: {(result['importances_mean'] > 0).mean():.0%}   ({rmse=:.3f}){Style.RESET_ALL}\")\n",
    "    importance_df = pd.DataFrame({'importance': result['importances_mean'],\n",
    "                        'std': result['importances_std']}, index=X_va.columns).sort_values('importance', ascending=False)\n",
    "    importance_df['ComputationTypeId'] = concepts.set_index('Name').ComputationTypeId\n",
    "    importance_df.fillna({'ComputationTypeId': 'Player'}, inplace=True)\n",
    "    display(importance_df.head(50))\n",
    "    print()\n",
    "    break\n",
    "    \n",
    "# Keep the good features for later\n",
    "good_features = list(importance_df.query(\"importance > 0\").index)\n",
    "good_features = [f for f in good_features if f not in ['p_selection', 'p_exploration', 'p_playout', 'p_bounds']]\n",
    "\n",
    "# 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb_params = {'grow_policy': 'SymmetricTree', \n",
    "#              'n_estimators': 800, \n",
    "#              'learning_rate': 0.08617153230342124, \n",
    "#              'l2_leaf_reg': 1.0036132233587023, \n",
    "#              'max_depth': 10, \n",
    "#              'colsample_bylevel': 0.734514897063923, \n",
    "#              'subsample': 0.994540769511675, \n",
    "#              'random_strength': 0.5393480589423867, \n",
    "#              'verbose': False}\n",
    "# model = catboost.CatBoostRegressor(**cb_params, cat_features= train_pd[good_features].columns[train_pd[good_features].dtypes == 'category'].values)\n",
    "# cross_validate_model(model, features=good_features, label=f\"CatBoost\", save_models=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('DDPM.py', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "--------------------------------------------------\n",
      "Final feature dimension: 245\n",
      "Numerical features: 233\n",
      "One-hot encoded features: 12\n",
      "[-8.68539385e-02 -1.11658608e+00 -1.94434868e-01 -2.54796814e-01\n",
      " -8.17215535e-01 -6.86522632e-01 -7.82939801e-01  7.19844932e-02\n",
      "  5.97947713e-01 -8.65652081e-01 -4.88440335e-01 -3.00534112e-01\n",
      " -6.47426075e-01 -4.63853804e-01  1.71008189e-01  5.19172942e-01\n",
      " -6.94064146e-01 -4.84283315e-01 -4.15705576e-01 -5.51430165e-03\n",
      " -5.97016031e-02  1.45577056e-01 -4.58098922e-02 -1.93830494e-01\n",
      " -4.80429664e-01 -3.19020148e-02  7.38969544e-03 -1.44789224e-01\n",
      "  2.12808866e+00 -3.03980860e-01  7.20563240e-01 -4.25650282e-02\n",
      "  1.56020356e+00 -2.45705505e-01 -4.36082482e-02 -6.76305708e-02\n",
      " -1.26578173e+00 -7.54916199e-01 -2.85642219e-01 -3.21832663e-02\n",
      "  1.63165036e+00  5.00260840e-01  2.08736394e-02 -3.27674587e-02\n",
      " -3.82369434e-01 -4.43589413e-03 -1.52146416e-01  1.30869910e+00\n",
      "  4.79142796e-01 -1.63821876e-02 -9.69807447e-02 -8.61980677e-01\n",
      " -9.11901118e-01 -3.72378606e-01 -7.99091174e-01 -1.31861755e+00\n",
      " -9.90229131e-01  5.18917811e-01 -1.07710217e-01 -3.17718257e-02\n",
      " -1.76861423e-01 -1.88742340e-01 -2.25804133e-01 -4.76113844e-01\n",
      " -3.47124362e-01  1.85951660e+00  1.28787454e-01  9.62422753e-01\n",
      " -1.00016766e+00 -4.03068764e-01  6.69948998e-01  5.36265630e-02\n",
      " -1.79742834e-01  1.47466940e+00 -8.12361188e-02 -5.77497299e-01\n",
      " -8.00907956e-02  4.03674430e-01  2.60084574e-01 -7.14839376e-01\n",
      "  5.11730798e-01  7.73074787e-01  5.59755455e-03  1.92465034e-01\n",
      " -4.93724481e-01 -3.94180809e-01 -3.07324698e-02 -8.81991783e-01\n",
      " -4.38007443e-01 -3.23407999e-01 -8.88177135e-02 -2.19506033e-01\n",
      " -1.82998689e-01 -3.21744792e-02  8.24345583e-01  2.52770112e-02\n",
      "  3.38221419e-01  7.78950743e-01 -8.34836482e-02 -4.25233308e-02\n",
      " -2.80354712e-01 -2.10192689e-01 -6.51527977e-01 -2.88699510e-01\n",
      "  4.02565720e-01 -1.86406638e-01 -3.11088333e-01 -8.96761345e-02\n",
      " -6.90065894e-01 -1.42801230e-01 -1.23345024e-01  3.58137905e-01\n",
      " -2.97004784e-01  2.90635086e+00 -2.99906354e-01  2.96859144e-01\n",
      " -1.53980783e-01 -2.40887488e-01 -1.88174356e-02 -1.62805589e-01\n",
      " -3.41709279e-01 -1.66829216e+00 -4.57325621e-01  1.00175739e+00\n",
      " -1.85828686e-01 -1.00201522e+00 -9.81721285e-01 -1.69575755e-01\n",
      "  3.94638453e-01  1.04573435e+00 -2.36476866e-02 -2.43200639e-01\n",
      "  7.31476930e+00 -2.56593841e-01 -1.77097721e-01  5.57251502e-01\n",
      " -2.81688758e-01 -8.99663171e-01  9.80290170e-01 -3.17686849e-02\n",
      " -2.98971053e-01 -2.91696529e-01 -4.80006981e-01 -7.99091174e-01\n",
      " -1.85797806e-01 -2.49056635e-01 -4.58023692e-01 -9.42519681e-02\n",
      " -1.18339288e-01  9.47604324e-01 -4.12735249e-01 -5.40756377e-02\n",
      " -9.90205698e-01 -7.26376295e-01 -6.27690487e-02 -3.63981583e-01\n",
      " -4.70292405e-01  4.10820275e-01 -1.92428173e-01  6.13917879e-01\n",
      "  4.21539943e-01 -5.97858819e-01 -1.44674403e-01  2.41831712e+00\n",
      " -7.39478377e-01  6.58531765e-01 -6.37090888e-02  8.53525375e-01\n",
      "  9.61170550e-01 -4.43801415e-01 -3.17744187e-02 -6.19022776e-02\n",
      "  7.74886983e-01 -5.99643548e-01 -2.49153740e-01 -3.41180713e-01\n",
      " -2.46374745e-01 -6.84559159e-02 -7.41144500e-01 -2.85777004e-01\n",
      " -9.65279108e-01 -1.65661766e-01  5.24055615e-01 -1.19145138e-01\n",
      " -1.05452491e-01 -5.00260840e-01  3.21750659e+00  1.61587285e-01\n",
      "  3.53611840e-01  6.06653132e+00 -5.17783949e-01 -1.33124744e-01\n",
      "  1.27326370e+00 -3.17695554e-02 -3.05525511e-01 -3.82369434e-01\n",
      " -2.36301875e-01  2.10053599e-01 -1.16310665e-01 -1.90774106e-01\n",
      " -1.92368239e-01 -7.01918315e-02 -7.00967543e-02 -5.11233583e-01\n",
      "  9.02212885e-02 -1.37115386e-01 -1.59156506e-01 -2.67390996e-01\n",
      " -2.27753064e-01 -1.50887475e-01 -3.17639179e-02 -7.43003380e-01\n",
      "  5.61794714e-01 -1.90411580e-01 -2.85636883e-01  1.94010641e-01\n",
      " -1.04896365e-01 -1.74111803e-01 -2.51944410e-01 -4.78728355e-01\n",
      " -3.81127640e-01 -3.31414332e-01  6.89362878e+00 -2.62617429e-01\n",
      " -8.67126380e-02 -1.75869123e-01  1.63726095e+00 -8.08217575e-01\n",
      " -3.16428292e-01 -4.70649377e-01 -2.84273243e-01 -1.83265042e-01\n",
      " -1.46365378e-01  0.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "  1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "kf = GroupShuffleSplit(n_splits=5, random_state=1)\n",
    "oof_predictions = np.zeros_like(y)\n",
    "models = []\n",
    "rmse_scores = []\n",
    "\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(train_pd, groups=groups)):\n",
    "    print(f\"\\nFold {fold + 1}/5\")\n",
    "    print(\"-\" * 50)\n",
    "    X_tr = train_pd.iloc[idx_tr]\n",
    "    X_va = train_pd.iloc[idx_va]\n",
    "    y_tr = y[idx_tr]\n",
    "    y_va = y[idx_va]\n",
    "    X_train_processed, X_val_processed,_ = prepare_data(X_tr, y_tr, good_features, val_pd=X_va)\n",
    "    print(X_train_processed[0])\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "--------------------------------------------------\n",
      "Final feature dimension: 245\n",
      "Numerical features: 233\n",
      "One-hot encoded features: 12\n",
      "Using device: cuda\n",
      "Model input dimension: 245\n",
      "Model hidden dimension: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 46/46 [00:03<00:00, 11.84it/s, loss=0.980287]\n",
      "Epoch 2/200: 100%|██████████| 46/46 [00:03<00:00, 11.94it/s, loss=0.870125]\n",
      "Epoch 3/200: 100%|██████████| 46/46 [00:03<00:00, 12.15it/s, loss=0.946059]\n",
      "Epoch 4/200: 100%|██████████| 46/46 [00:03<00:00, 12.45it/s, loss=0.850182]\n",
      "Epoch 5/200: 100%|██████████| 46/46 [00:03<00:00, 11.73it/s, loss=0.487002]\n",
      "predicting: 100%|██████████| 12/12 [00:12<00:00,  1.07s/it, sampling=5/5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n",
      "Training Loss: 0.626135\n",
      "Validation RMSE: 0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 100%|██████████| 46/46 [00:04<00:00, 11.42it/s, loss=0.371650]\n",
      "Epoch 7/200: 100%|██████████| 46/46 [00:03<00:00, 11.96it/s, loss=0.343012]\n",
      "Epoch 8/200: 100%|██████████| 46/46 [00:03<00:00, 12.82it/s, loss=0.352162]\n",
      "Epoch 9/200: 100%|██████████| 46/46 [00:03<00:00, 12.26it/s, loss=0.341416]\n",
      "Epoch 10/200: 100%|██████████| 46/46 [00:03<00:00, 11.76it/s, loss=0.336322]\n",
      "predicting: 100%|██████████| 12/12 [00:12<00:00,  1.08s/it, sampling=5/5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\n",
      "Training Loss: 0.320138\n",
      "Validation RMSE: 0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 100%|██████████| 46/46 [00:03<00:00, 11.70it/s, loss=0.294910]\n",
      "Epoch 12/200: 100%|██████████| 46/46 [00:03<00:00, 11.75it/s, loss=0.296162]\n",
      "Epoch 13/200: 100%|██████████| 46/46 [00:03<00:00, 11.71it/s, loss=0.308050]\n",
      "Epoch 14/200: 100%|██████████| 46/46 [00:03<00:00, 12.17it/s, loss=0.301861]\n",
      "Epoch 15/200: 100%|██████████| 46/46 [00:03<00:00, 12.98it/s, loss=0.274884]\n",
      "predicting: 100%|██████████| 12/12 [00:13<00:00,  1.11s/it, sampling=5/5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:\n",
      "Training Loss: 0.279249\n",
      "Validation RMSE: 0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: 100%|██████████| 46/46 [00:03<00:00, 11.67it/s, loss=0.260330]\n",
      "Epoch 17/200: 100%|██████████| 46/46 [00:03<00:00, 12.50it/s, loss=0.247656]\n",
      "Epoch 18/200: 100%|██████████| 46/46 [00:03<00:00, 11.87it/s, loss=0.250868]\n",
      "Epoch 19/200: 100%|██████████| 46/46 [00:03<00:00, 12.08it/s, loss=0.289615]\n",
      "Epoch 20/200: 100%|██████████| 46/46 [00:03<00:00, 13.39it/s, loss=0.245521]\n",
      "predicting: 100%|██████████| 12/12 [00:13<00:00,  1.11s/it, sampling=5/5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:\n",
      "Training Loss: 0.254109\n",
      "Validation RMSE: 0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/200: 100%|██████████| 46/46 [00:03<00:00, 11.94it/s, loss=0.233399]\n",
      "Epoch 22/200: 100%|██████████| 46/46 [00:03<00:00, 12.92it/s, loss=0.263374]\n",
      "Epoch 23/200: 100%|██████████| 46/46 [00:03<00:00, 11.98it/s, loss=0.288713]\n",
      "Epoch 24/200: 100%|██████████| 46/46 [00:03<00:00, 12.43it/s, loss=0.270813]\n",
      "Epoch 25/200: 100%|██████████| 46/46 [00:03<00:00, 12.15it/s, loss=0.241018]\n",
      "predicting: 100%|██████████| 12/12 [00:13<00:00,  1.09s/it, sampling=5/5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:\n",
      "Training Loss: 0.241473\n",
      "Validation RMSE: 0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/200: 100%|██████████| 46/46 [00:03<00:00, 11.68it/s, loss=0.249771]\n",
      "Epoch 27/200: 100%|██████████| 46/46 [00:03<00:00, 11.67it/s, loss=0.228923]\n",
      "Epoch 28/200: 100%|██████████| 46/46 [00:03<00:00, 12.43it/s, loss=0.238562]\n",
      "Epoch 29/200: 100%|██████████| 46/46 [00:03<00:00, 11.87it/s, loss=0.208370]\n",
      "Epoch 30/200: 100%|██████████| 46/46 [00:03<00:00, 12.41it/s, loss=0.243210]\n",
      "predicting: 100%|██████████| 12/12 [00:13<00:00,  1.09s/it, sampling=5/5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30:\n",
      "Training Loss: 0.229068\n",
      "Validation RMSE: 0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/200: 100%|██████████| 46/46 [00:03<00:00, 11.88it/s, loss=0.240502]\n",
      "Epoch 32/200: 100%|██████████| 46/46 [00:03<00:00, 12.34it/s, loss=0.221933]\n",
      "Epoch 33/200: 100%|██████████| 46/46 [00:03<00:00, 13.09it/s, loss=0.226973]\n",
      "Epoch 34/200: 100%|██████████| 46/46 [00:03<00:00, 12.08it/s, loss=0.212471]\n",
      "Epoch 35/200: 100%|██████████| 46/46 [00:03<00:00, 12.10it/s, loss=0.219766]\n",
      "predicting: 100%|██████████| 12/12 [00:13<00:00,  1.09s/it, sampling=5/5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35:\n",
      "Training Loss: 0.224839\n",
      "Validation RMSE: 0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/200: 100%|██████████| 46/46 [00:03<00:00, 11.93it/s, loss=0.218647]\n",
      "Epoch 37/200: 100%|██████████| 46/46 [00:03<00:00, 11.67it/s, loss=0.233669]\n",
      "Epoch 38/200: 100%|██████████| 46/46 [00:03<00:00, 12.21it/s, loss=0.231776]\n",
      "Epoch 39/200: 100%|██████████| 46/46 [00:03<00:00, 12.14it/s, loss=0.242743]\n",
      "Epoch 40/200: 100%|██████████| 46/46 [00:03<00:00, 12.03it/s, loss=0.229923]\n",
      "predicting: 100%|██████████| 12/12 [00:13<00:00,  1.11s/it, sampling=5/5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40:\n",
      "Training Loss: 0.219655\n",
      "Validation RMSE: 0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/200: 100%|██████████| 46/46 [00:03<00:00, 13.13it/s, loss=0.231490]\n",
      "Epoch 42/200: 100%|██████████| 46/46 [00:03<00:00, 11.72it/s, loss=0.207992]\n",
      "Epoch 43/200: 100%|██████████| 46/46 [00:03<00:00, 11.96it/s, loss=0.211223]\n",
      "Epoch 44/200: 100%|██████████| 46/46 [00:03<00:00, 11.77it/s, loss=0.224658]\n",
      "Epoch 45/200: 100%|██████████| 46/46 [00:03<00:00, 12.10it/s, loss=0.196200]\n",
      "predicting: 100%|██████████| 12/12 [00:13<00:00,  1.12s/it, sampling=5/5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45:\n",
      "Training Loss: 0.216354\n",
      "Validation RMSE: 0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/200: 100%|██████████| 46/46 [00:04<00:00, 11.16it/s, loss=0.224638]\n",
      "Epoch 47/200: 100%|██████████| 46/46 [00:03<00:00, 12.67it/s, loss=0.224382]\n",
      "Epoch 48/200: 100%|██████████| 46/46 [00:03<00:00, 11.90it/s, loss=0.205070]\n",
      "Epoch 49/200: 100%|██████████| 46/46 [00:03<00:00, 12.09it/s, loss=0.226692]\n",
      "Epoch 50/200: 100%|██████████| 46/46 [00:03<00:00, 13.35it/s, loss=0.225153]\n",
      "predicting: 100%|██████████| 12/12 [00:13<00:00,  1.11s/it, sampling=5/5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50:\n",
      "Training Loss: 0.213128\n",
      "Validation RMSE: 0.540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/200: 100%|██████████| 46/46 [00:03<00:00, 12.20it/s, loss=0.201420]\n",
      "Epoch 52/200: 100%|██████████| 46/46 [00:03<00:00, 12.30it/s, loss=0.174860]\n",
      "Epoch 53/200: 100%|██████████| 46/46 [00:04<00:00, 11.38it/s, loss=0.227592]\n",
      "Epoch 54/200: 100%|██████████| 46/46 [00:03<00:00, 12.06it/s, loss=0.202336]\n",
      "Epoch 55/200: 100%|██████████| 46/46 [00:03<00:00, 12.29it/s, loss=0.203990]\n",
      "predicting: 100%|██████████| 12/12 [00:13<00:00,  1.13s/it, sampling=5/5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55:\n",
      "Training Loss: 0.206178\n",
      "Validation RMSE: 0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/200: 100%|██████████| 46/46 [00:03<00:00, 11.54it/s, loss=0.191949]\n",
      "Epoch 57/200: 100%|██████████| 46/46 [00:03<00:00, 12.38it/s, loss=0.260081]\n",
      "Epoch 58/200: 100%|██████████| 46/46 [00:03<00:00, 11.74it/s, loss=0.202103]\n",
      "Epoch 59/200: 100%|██████████| 46/46 [00:04<00:00, 11.05it/s, loss=0.195854]\n",
      "Epoch 60/200: 100%|██████████| 46/46 [00:03<00:00, 12.75it/s, loss=0.208237]\n",
      "predicting: 100%|██████████| 12/12 [00:13<00:00,  1.11s/it, sampling=5/5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60:\n",
      "Training Loss: 0.208504\n",
      "Validation RMSE: 0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/200: 100%|██████████| 46/46 [00:04<00:00, 10.02it/s, loss=0.214827]\n",
      "Epoch 62/200: 100%|██████████| 46/46 [00:03<00:00, 12.10it/s, loss=0.197370]\n",
      "Epoch 63/200: 100%|██████████| 46/46 [00:04<00:00, 10.59it/s, loss=0.216107]\n",
      "Epoch 64/200: 100%|██████████| 46/46 [00:04<00:00, 10.29it/s, loss=0.190136]\n",
      "Epoch 65/200: 100%|██████████| 46/46 [00:03<00:00, 11.79it/s, loss=0.190392]\n",
      "predicting: 100%|██████████| 12/12 [00:13<00:00,  1.12s/it, sampling=5/5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65:\n",
      "Training Loss: 0.201527\n",
      "Validation RMSE: 0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/200: 100%|██████████| 46/46 [00:03<00:00, 11.60it/s, loss=0.214794]\n",
      "Epoch 67/200: 100%|██████████| 46/46 [00:03<00:00, 11.93it/s, loss=0.199595]\n",
      "Epoch 68/200: 100%|██████████| 46/46 [00:03<00:00, 12.18it/s, loss=0.200737]\n",
      "Epoch 69/200: 100%|██████████| 46/46 [00:04<00:00, 11.26it/s, loss=0.204654]\n",
      "Epoch 70/200: 100%|██████████| 46/46 [00:03<00:00, 12.70it/s, loss=0.188839]\n",
      "predicting:  50%|█████     | 6/12 [00:07<00:07,  1.33s/it, sampling=4/5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 38\u001b[0m\n\u001b[1;32m     34\u001b[0m X_train_processed, X_val_processed,_ \u001b[38;5;241m=\u001b[39m prepare_data(X_tr, y_tr, good_features, val_pd\u001b[38;5;241m=\u001b[39mX_va)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m model, trainer, val_rmse \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_diffusion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val_processed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_va\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_params\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m val_pred \u001b[38;5;241m=\u001b[39m predict_diffusion(model, trainer, X_val_processed, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     48\u001b[0m val_pred \u001b[38;5;241m=\u001b[39m val_pred\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \n",
      "File \u001b[0;32m<string>:283\u001b[0m, in \u001b[0;36mtrain_diffusion\u001b[0;34m(X, y, X_val, y_val, model_params, train_params)\u001b[0m\n",
      "File \u001b[0;32m<string>:243\u001b[0m, in \u001b[0;36mpredict_diffusion\u001b[0;34m(model, trainer, X, device, n_samples)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/comfyui/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:147\u001b[0m, in \u001b[0;36msample\u001b[0;34m(self, model, x, n_steps)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/comfyui/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/comfyui/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m<string>:79\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, t, noise)\u001b[0m\n",
      "File \u001b[0;32m<string>:72\u001b[0m, in \u001b[0;36mget_time_embedding\u001b[0;34m(self, t)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/comfyui/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/comfyui/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/comfyui/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/comfyui/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/comfyui/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m<string>:31\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, time)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "model_params = {\n",
    "    'hidden_dim': 1024\n",
    "}\n",
    "\n",
    "\n",
    "train_params = {\n",
    "    'batch_size': 4096,\n",
    "    'n_steps': 200,\n",
    "    'n_epochs': 200,\n",
    "    'learning_rate': 1e-4,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "kf = GroupShuffleSplit(n_splits=5, random_state=1)\n",
    "\n",
    "# 存储每个fold的结果\n",
    "oof_predictions = np.zeros_like(y)\n",
    "models = []\n",
    "rmse_scores = []\n",
    "\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(train_pd, groups=groups)):\n",
    "    print(f\"\\nFold {fold + 1}/5\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 准备当前fold的数据\n",
    "    X_tr = train_pd.iloc[idx_tr]\n",
    "    X_va = train_pd.iloc[idx_va]\n",
    "    y_tr = y[idx_tr]\n",
    "    y_va = y[idx_va]\n",
    "    \n",
    "\n",
    "    X_train_processed, X_val_processed,_ = prepare_data(X_tr, y_tr, good_features, val_pd=X_va)\n",
    "\n",
    "    \n",
    "    # 训练模型\n",
    "    model, trainer, val_rmse = train_diffusion(\n",
    "        X_train_processed, \n",
    "        y_tr,\n",
    "        X_val_processed,\n",
    "        y_va,\n",
    "        model_params,\n",
    "        train_params\n",
    "    )\n",
    "\n",
    "    val_pred = predict_diffusion(model, trainer, X_val_processed, device='cuda')\n",
    "    val_pred = val_pred.clip(-1, 1) \n",
    "    \n",
    "    oof_predictions[idx_va] = val_pred\n",
    "    models.append(model)\n",
    "    rmse_scores.append(val_rmse)\n",
    "    \n",
    "    fold_rmse = np.sqrt(mean_squared_error(y_va, val_pred))\n",
    "    print(f\"Fold {fold + 1} Final RMSE: {fold_rmse:.3f}\")\n",
    "\n",
    "# 计算总体RMSE\n",
    "overall_rmse = np.sqrt(mean_squared_error(y, oof_predictions))\n",
    "print(f\"\\nOverall RMSE: {overall_rmse:.3f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comfyui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
